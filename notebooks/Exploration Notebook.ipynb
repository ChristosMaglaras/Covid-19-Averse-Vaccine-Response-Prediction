{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load in all three datasets for each year\n",
    "symptoms19 = pd.read_csv('../data/2019/symptoms19.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "data19     = pd.read_csv('../data/2019/data19.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "vax19      = pd.read_csv('../data/2019/vax19.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "\n",
    "symptoms20 = pd.read_csv('../data/2020/symptoms20.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "data20     = pd.read_csv('../data/2020/data20.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "vax20      = pd.read_csv('../data/2020/vax20.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "\n",
    "symptoms21 = pd.read_csv('../data/2021/symptoms21.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "data21     = pd.read_csv('../data/2021/data21.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "vax21      = pd.read_csv('../data/2021/vax21.csv', index_col=['VAERS_ID'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were no Covid-19 vaccinations untill 2020\n",
    "(vax19['VAX_TYPE']=='COVID19').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can combine the three datasets for the years containing covid vaccinations on the index\n",
    "combined_vax = pd.concat([vax20, vax21])\n",
    "combined_data = pd.concat([data20, data21])\n",
    "combined_symptoms = pd.concat([symptoms20, symptoms21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_vax[combined_vax['VAX_TYPE'] == 'COVID19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datavax = pd.merge(combined_data, combined_vax, on='VAERS_ID', how='right')\n",
    "dvs = pd.merge(datavax, combined_symptoms, on='VAERS_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating covid-19 vaccinations for the base dataframe\n",
    "df = dvs[dvs['VAX_TYPE'] == 'COVID19']\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets isolate all the text data to deal with later\n",
    "df_text_cols = df[['SYMPTOM_TEXT', 'LAB_DATA', 'OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'ALLERGIES', 'SYMPTOM1', 'SYMPTOM2', 'SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets drop unessesary columns\n",
    "# Lets move this untill after EDA is completed\n",
    "# df.drop(axis=1, inplace=True, columns=['CAGE_YR', 'CAGE_MO', 'RPT_DATE', 'ER_VISIT','V_FUNDBY', 'SPLTTYPE', 'FORM_VERS',\n",
    "#                                        'TODAYS_DATE','OFC_VISIT', 'ER_ED_VISIT', 'VAX_TYPE', 'VAX_NAME', 'VAX_LOT',\n",
    "#                                        'SYMPTOM_TEXT','LAB_DATA','OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'ALLERGIES',\n",
    "#                                        'SYMPTOM1', 'SYMPTOM2','SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5', 'VAX_DATE', 'ONSET_DATE',\n",
    "#                                       'PRIOR_VAX', 'DATEDIED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIED'] = df['DIED'].fillna(0)\n",
    "df['DIED'] = df['DIED'].replace('Y', 1)\n",
    "\n",
    "df['SEX'] = df['SEX'].replace('U', '0')\n",
    "df['SEX'] = df['SEX'].replace('F', '0')\n",
    "df['SEX'] = df['SEX'].replace('M', '1')\n",
    "\n",
    "df['L_THREAT'] = df['L_THREAT'].fillna(0)\n",
    "df['L_THREAT'] = df['L_THREAT'].replace('Y', 1)\n",
    "\n",
    "df['HOSPITAL'] = df['HOSPITAL'].fillna(0)\n",
    "df['HOSPITAL'] = df['HOSPITAL'].replace('Y', 1)\n",
    "\n",
    "df['HOSPDAYS'] = df['HOSPDAYS'].fillna(0)\n",
    "\n",
    "df['X_STAY'] = df['X_STAY'].fillna(0)\n",
    "df['X_STAY'] = df['X_STAY'].replace('Y', 1)\n",
    "\n",
    "df['DISABLE'] = df['DISABLE'].fillna(0)\n",
    "df['DISABLE'] = df['DISABLE'].replace('Y', 1)\n",
    "\n",
    "df['RECOVD'] = df['RECOVD'].fillna(0)\n",
    "df['RECOVD'] = df['RECOVD'].replace('U', 0)\n",
    "df['RECOVD'] = df['RECOVD'].replace('N', 0)\n",
    "df['RECOVD'] = df['RECOVD'].replace('Y', 1)\n",
    "\n",
    "df['BIRTH_DEFECT'] = df['BIRTH_DEFECT'].fillna(0)\n",
    "df['BIRTH_DEFECT'] = df['BIRTH_DEFECT'].replace('Y', 1)\n",
    "\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].fillna(0)\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].replace('7+', 7)\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].replace('UNK', 1)\n",
    "\n",
    "df['SYMPTOMVERSION2'] = df['SYMPTOMVERSION2'].fillna(0)\n",
    "df['SYMPTOMVERSION3'] = df['SYMPTOMVERSION3'].fillna(0)\n",
    "df['SYMPTOMVERSION4'] = df['SYMPTOMVERSION4'].fillna(0)\n",
    "df['SYMPTOMVERSION5'] = df['SYMPTOMVERSION5'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['VAX_MANU'], prefix='BRAND: ')],axis=1).drop(['VAX_MANU'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['VAX_SITE'], prefix='VAX_SITE: ')],axis=1).drop(['VAX_SITE'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['VAX_ROUTE'], prefix='VAX_ROUTE: ')],axis=1).drop(['VAX_ROUTE'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['V_ADMINBY'], prefix='ADMINBY: ')],axis=1).drop(['V_ADMINBY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill according to average\n",
    "df['AGE_YRS'] = df['AGE_YRS'].fillna(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmno = df['NUMDAYS']\n",
    "df['NUMDAYS'] = lmno.where(lmno<120, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX'] = df['SEX'].astype(int)\n",
    "df['AGE_YRS'] = df['AGE_YRS'].astype(int)\n",
    "df['HOSPDAYS'] = df['HOSPDAYS'].astype(int)\n",
    "df['NUMDAYS'] = df['NUMDAYS'].astype(int)\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].astype(int)\n",
    "\n",
    "df['SYMPTOMVERSION1'] = df['SYMPTOMVERSION1'].astype('category')\n",
    "df['SYMPTOMVERSION2'] = df['SYMPTOMVERSION2'].astype('category')\n",
    "df['SYMPTOMVERSION3'] = df['SYMPTOMVERSION3'].astype('category')\n",
    "df['SYMPTOMVERSION4'] = df['SYMPTOMVERSION4'].astype('category')\n",
    "df['SYMPTOMVERSION5'] = df['SYMPTOMVERSION5'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labelbinarizer on STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['STATE'].replace(['AS', 'VI', 'MP', 'Ca', 'XB', 'FM', 'MH', 'GU'], 'OTH', inplace=True)\n",
    "df['STATE'] = df['STATE'].fillna('N/A')\n",
    "\n",
    "df['STATE'].value_counts()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df['STATE'])\n",
    "df['STATE'] = label_encoder.transform(df['STATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALLERGIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALLERGIES'] = df['ALLERGIES'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist = ['no', 'no known allergies', 'unknown', 'none known', 'n/a', 'none reported', 'na', 'none.',\n",
    "            'no known drug allergies', 'no allergies', 'na', 'no known', 'no known allergies.', 'none listed', \n",
    "           'unk', 'none known.']\n",
    "\n",
    "df['ALLERGIES'] = df['ALLERGIES'].fillna('none')\n",
    "df['ALLERGIES'] = df['ALLERGIES'].replace('penicillin|sulfa', 'penicillin')\n",
    "df['ALLERGIES'] = df['ALLERGIES'].replace(nonelist, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['ALLERGIES']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>30].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datufrayme = pd.Series(allall3).str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy.remove('penicillin|sulfa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del listy[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.join(datufrayme[listy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALLERGIES\n",
    "## CURRENT ILLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CUR_ILL'] = df['CUR_ILL'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist = ['no', 'unknown', 'none.', 'none reported', 'n/a', 'na', 'none known', 'denies', 'none noted', '0', 'no illness',\n",
    "           'none listed', 'not known', 'no known', 'non', 'no acute illnesses', 'no.', 'denied', 'see below', 'no illnesses',\n",
    "            'unk', 'unkown', 'none documented', 'none stated', 'nothing', 'none known.', 'unknown.', 'no known illnesses',\n",
    "            'n/a.','no e', 'none reported.', 'no acute illness']\n",
    "\n",
    "df['CUR_ILL'] = df['CUR_ILL'].fillna('none')\n",
    "df['CUR_ILL'] = df['CUR_ILL'].replace(nonelist, 'none')\n",
    "df['CUR_ILL'] = df['CUR_ILL'].replace(['covid 19', 'covid', 'covid- 19 diagnosis 12/11/2020 asymptomatic', 'covid-19 (diagnosed 10/26/20)', 'covid-19  (diagnosed 10/26/20)'], 'covid-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['CUR_ILL']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "            \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "            \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>13].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "    \n",
    "datufrayme = pd.Series(allall3).str.get_dummies()\n",
    "\n",
    "listy.remove('alcohol use disorder|facial laceration|alcohol intoxication|secondary syphillis')\n",
    "listy.remove('elevated troponin i level elevated troponin i level        elevated brain natriuretic peptide (bnp) level elevated brain natriuretic peptide (bnp) level        dyspnea       chest pain        atrial fibrillation with rapid ventricular response (hcc) atrial fibrillation with rapid ventricular response|initial encounter       hyponatremia hyponatremia')\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "    \n",
    "df = df.join(datufrayme[listy], lsuffix=\" cur_ill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HISTORY'] = df['HISTORY'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist = ['no', 'unknown', 'none.', 'none reported', 'n/a', 'na', 'none known', 'denies', 'none noted', '0', 'no illness',\n",
    "           'none listed', 'not known', 'no known', 'non', 'no acute illnesses', 'no.', 'denied', 'see below', 'no illnesses',\n",
    "            'unk', 'unkown', 'none documented', 'none stated', 'nothing', 'none known.', 'unknown.', 'as above', 'no known illnesses',\n",
    "            'n/a.','no e', 'none reported.', 'medical history/concurrent conditions: no adverse event (no reported medical history)',\n",
    "           'medical history/concurrent conditions: no adverse event (no reported medical history.)', 'see above', 'medical history/concurrent conditions: no adverse event',\n",
    "           'medical history/concurrent conditions: no adverse event (no medical history reported.)', 'medical history/concurrent conditions: no adverse event (no medical history reported)',\n",
    "           'medical history/concurrent conditions: no adverse event (medical history not provided)', 'comments: list of non-encoded patient relevant history: patient other relevant history 1: none',\n",
    "           ]\n",
    "\n",
    "df['HISTORY'] = df['HISTORY'].fillna('none')\n",
    "df['HISTORY'] = df['HISTORY'].replace(nonelist, 'none')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: covid-19', 'covid-19')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: hypertension', 'hypertension')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: penicillin allergy', 'penicillin allergy')\n",
    "df['HISTORY'] = df['HISTORY'].replace(['medical history/concurrent conditions: asthma','mild asthma','exercise induced asthma'], 'asthma')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: blood pressure high', 'high blood pressure')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: sulfonamide allergy', 'sulfonamide allergy')\n",
    "df['HISTORY'] = df['HISTORY'].replace(['diabetic', 'type 2 diabetes', 'type 1 diabetes'], 'diabetes')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: migraine', 'migraines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['HISTORY']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "            \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "            \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>40].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "    \n",
    "datufrayme = pd.Series(allall3).str.get_dummies()\n",
    "\n",
    "listy.remove('cerebral palsy|anxiety|crohns|bipolar|gerd|nutrition deficiency|iron deficiency')\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "    \n",
    "df = df.join(datufrayme[listy], lsuffix=\" history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER_MEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OTHER_MEDS'] = df['OTHER_MEDS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist = ['unknown', 'no', 'none.', 'n/a', 'none reported', 'unk', 'none known', ';', 'not known', 'na', 'denies', ';  ;', \n",
    "           'nothing']\n",
    "\n",
    "df['OTHER_MEDS'] = df['OTHER_MEDS'].fillna('none')\n",
    "df['OTHER_MEDS'] = df['OTHER_MEDS'].replace(nonelist, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['OTHER_MEDS']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "            \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "            \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>20].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "    \n",
    "datufrayme = pd.Series(allall3).str.get_dummies()\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "    \n",
    "df = df.join(datufrayme[listy], lsuffix=\" meds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX']\n",
    "fig5, ax5 = plt.subplots(figsize=(8,8))\n",
    "sns.histplot(df['SEX'], ax=ax5, bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symplist = [df['SYMPTOM1'].values, df['SYMPTOM2'].values, df['SYMPTOM3'].values,\n",
    "            df['SYMPTOM4'].values, df['SYMPTOM5'].values]\n",
    "sl = []\n",
    "\n",
    "for each in symplist:\n",
    "          for weach in each:\n",
    "            sl.append(weach)\n",
    "dfsl = pd.Series(sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcsym = dfsl.value_counts()\n",
    "vcsym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcsym = vcsym[vcsym > 1000]\n",
    "vcsym\n",
    "keys = []\n",
    "for each in vcsym.keys():\n",
    "    keys.append(str(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keys\n",
    "Y = vcsym.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,25))\n",
    "sns.barplot(Y, X, orient='h', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(8,30))\n",
    "sns.barplot(y=df['STATE'].value_counts().keys(), x=df['STATE'].value_counts().values, ax=ax2, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(df['AGE_YRS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIED'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(figsize=(8,8))\n",
    "sns.barplot(y=df['VAX_NAME'].value_counts().keys(), x=df['VAX_NAME'].value_counts().values, ax=ax3, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in df['VAX_NAME'].value_counts().index:\n",
    "    tdf = df[df['VAX_NAME']==each]\n",
    "    print(len(tdf[tdf['DIED']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VAX_NAME'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr().head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(figsize =(35,30))\n",
    "sns.heatmap(df.corr(), ax=ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjan = df[df['BRAND: _JANSSEN']==1]\n",
    "dfmod = df[df['BRAND: _MODERNA']==1]\n",
    "dfpfi = df[df['BRAND: _PFIZER\\\\BIONTECH']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmod.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpfi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=1, inplace=True, columns=['CAGE_YR', 'CAGE_MO', 'RPT_DATE', 'ER_VISIT','V_FUNDBY', 'SPLTTYPE', 'FORM_VERS',\n",
    "                                       'TODAYS_DATE','OFC_VISIT', 'ER_ED_VISIT', 'VAX_TYPE', 'VAX_NAME', 'VAX_LOT',\n",
    "                                       'SYMPTOM_TEXT','LAB_DATA','OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'ALLERGIES',\n",
    "                                       'SYMPTOM1', 'SYMPTOM2','SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5', 'VAX_DATE', 'ONSET_DATE',\n",
    "                                      'PRIOR_VAX', 'DATEDIED', 'SYMPTOMVERSION1', 'SYMPTOMVERSION2', 'SYMPTOMVERSION3',\n",
    "                                      'SYMPTOMVERSION4', 'SYMPTOMVERSION5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcols = list(df.columns)\n",
    "allcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AGE_YRS', 'SEX', 'DIED', 'L_THREAT', 'HOSPITAL','HOSPDAYS', 'X_STAY', 'DISABLE', 'RECOVD', 'NUMDAYS', 'BIRTH_DEFECT',\n",
    "'VAX_DOSE_SERIES', 'BRAND: _JANSSEN', 'BRAND: _MODERNA','BRAND: _PFIZER\\BIONTECH', 'BRAND: _UNKNOWN MANUFACTURER',\n",
    "'VAX_SITE: _AR', 'VAX_SITE: _GM', 'VAX_SITE: _LA', 'VAX_SITE: _LG','VAX_SITE: _LL', 'VAX_SITE: _OT', 'VAX_SITE: _RA',\n",
    "'VAX_SITE: _]\n",
    "df[cols] = df[cols].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('VAERS_ID')\n",
    "df.drop(columns = ['RECVDATE', 'CAGE_MO', 'CAGE_YR', 'RPT_DATE', 'SYMPTOM_TEXT', 'DIED',\n",
    "                  'DATEDIED', 'L_THREAT', 'ER_VISIT', 'HOSPDAYS', 'X_STAY', 'RECOVD', 'VAX_DATE', 'ONSET_DATE',\n",
    "                  'NUMDAYS', 'LAB_DATA', 'V_FUNDBY', 'OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE', \n",
    "                  'FORM_VERS', 'TODAYS_DATE', 'OFC_VISIT', 'ER_ED_VISIT', 'ALLERGIES', 'VAX_TYPE', 'VAX_LOT', \n",
    "                  'SYMPTOM1', 'SYMPTOM2','SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5','SYMPTOMVERSION1', 'SYMPTOMVERSION2',\n",
    "                   'SYMPTOMVERSION3','SYMPTOMVERSION4', 'SYMPTOMVERSION5', 'VAX_NAME'],\n",
    "       axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(int)\n",
    "df['STATE'] = df['STATE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.drop('VAERS_ID', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "x = df.drop(columns = ['HOSPITAL'])\n",
    "y = df['HOSPITAL']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .2)\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rfc.predict(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(estimator=rfc, y_true=yval, X = xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(estimator=rfc, y_true=yval, X = xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(estimator=rfc, y_true=yval, X = xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(xtrain, xval, ytrain, yval)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3b6ce992017a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.astype(int)\n",
    "df['STATE'] = df['STATE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain, label=ytrain, missing=0, enable_categorical=True)\n",
    "dtest  = xgb.DMatrix(xtest, label=ytest, missing=0)\n",
    "dval   = xgb.DMatrix(xval, label=yval, missing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_tune_xgb(max_depth, gamma, n_estimators ,learning_rate, scale_pos_weight, min_child_weight, colsample_bytree, subsample):\n",
    "    params = {'max_depth'       : int(max_depth),\n",
    "              'gamma'           : gamma,\n",
    "              'n_estimators'    : int(n_estimators),\n",
    "              'learning_rate'   : learning_rate,\n",
    "              'subsample'       : subsample,\n",
    "              'eval_metric'     : 'rmse',\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'scale_pos_weight': scale_pos_weight,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'tree_method'     : 'gpu_hist'}\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=200, nfold=5)\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth' : (1, 20),\n",
    "                        'gamma'            : (0, 2),\n",
    "                        'subsample'        : (0,1),           \n",
    "                        'learning_rate'    : (0,1),\n",
    "                        'n_estimators'     : (100,400),\n",
    "                        'scale_pos_weight' : (5,10),\n",
    "                        'min_child_weight' : (1,10),\n",
    "                        'colsample_bytree' : (0,1)} ,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_bo.maximize(n_iter=20, init_points=15, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = xgb_bo.max['params']\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "params['n_estimators'] = int(params['n_estimators'])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_opt= xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsopt = xgb_opt.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsopt.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predsopt.round(), ytrain)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(predsopt.round(), ytrain)\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(predsopt.round(), ytrain)\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.diagonal().sum()/cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predsopt.round(), ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsoptval = xgb_opt.predict(dval)\n",
    "print(classification_report(predsoptval.round(), yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss: 0.2705 - accuracy: 0.8928 - precision_9: 0.7092 - recall_9: 0.4204 - val_loss: 0.3487 - val_accuracy: 0.8827 - val_precision_9: 0.6594 - val_recall_9: 0.3908\n",
    "\n",
    "df.corr()['HOSPITAL'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swish is a recent activation function that is said to remedy the issues of ReLU. Lets put it to the test\n",
    "def swish(x, b = 1):\n",
    "    return (x * sigmoid(b * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newmod():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(176, input_dim=len(xtrain.columns), activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(88, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(44, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(22, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(11, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "estimator = newmod()\n",
    "estimator.compile(optimizer='nadam', \n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = estimator.fit(xtrain, ytrain, epochs=100, validation_data=(xval, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eleventh model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ninth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ninth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eighth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seventh model 1k\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seventh model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
