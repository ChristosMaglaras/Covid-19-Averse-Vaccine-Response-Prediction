{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 Averse Vaccine Response Prediction\n",
    "![vaccine brands](../data/images/vaccines.jpg)\n",
    "Author: Christos Maglaras<br>\n",
    "Date : 4/14/2021\n",
    "## Stakeholder\n",
    "This project is mainly focused on serving the induvidual by providing an prediction based on personal information of the possibility of a negative reaction from one of the Covid-19 vaccines. It could also be applied in a medical center such as a clinic or hospital to screen patients easily and quickly. If you would like to know your or anothers risk of illness from one of the three available vaccines you may enter some or all of your personal information into the following web form ~flask link~. Successfully being able to predict the outcome of a patient utilizing nothing more than an online form would be higly beneficial to the patient of course, but also the healthcare system by decreasing the amount of strain placed on hospitals. \n",
    "\n",
    "## Data\n",
    "The data utilized for this project has been sourced from the CDC VAERS system, a public dataset consisting of thirty years of domestic adverse vaccine events. Medical professionals and vaccine manufactures are required to report all adverse reactions that come to their attention. While they are required to submit records, anyone can submit a report of their experience. The data consists of general informations such as age and sex, vaccination information like the administration facility and brand, and health information such as preexisting illnesses, allergies, and medications they may take. This dataset contains roughly 70,000 records containing covid-19 vaccines, and is updated every two weeks with new records. You can collect the data [Here](https://vaers.hhs.gov/data/datasets.html?).\n",
    "![vaers](../data/images/vaers.png)\n",
    "\n",
    "## Business Understanding\n",
    "This system would alleviate some of the pressure from hospitals, freeing up resources so they can operate more effectively. The first way in which a system like this would help is as a first step screening method, filtering patients to at least notify their clinician of their risks. The second is that in avoiding the adverse reactions, the hospitals do not need to dedicate extra resources to the patient after the reaction. Aulthough we have here seventy thousand cases reporting adverse reactions, the US now has reached five million vaccinations of at least one dose, and three million full vaccinations, meaning that these adverse reactions are only 1.4% of all domestic vaccinations. This is not to say that the 1.4% are to be ignored, with the legal age of the vaccine being sixteen, that leaves two hundred thirty million people eligible for the vaccine in the us, 1.4% being three million.\n",
    "\n",
    "## Model\n",
    "The model that achieved the best results was xgboost optimized using the Bayesian Optimization technique. This achieved significantly better results than both the standard random forests and the neural network which were not able to produce informative models. Aulthough there is some difficulty differentiating between hospital-bound and those who are not, that is between patients who all had some sort of averse reaction. A real wold test might be more precice as it has been trained on the more difficult task of seperating two groups who are very similar to one another. \n",
    "\n",
    "## Contents\n",
    "```\n",
    "├── data\n",
    "|   ├── vaers_guide.pdf\n",
    "|   ├── images\n",
    "|   |   ├── vaccines.jpg\n",
    "|   |   └── vaers.mp4\n",
    "|   └── dataset\n",
    "|       ├── 2020\n",
    "|       |   ├── data20.csv\n",
    "|       |   ├── symptoms20.csv\n",
    "|       |   └── vax20.csv\n",
    "|       └── 2021\n",
    "|           ├── data21.csv\n",
    "|           ├── symptoms21.csv\n",
    "|           └── vax21.csv\n",
    "├── notebooks\n",
    "|   ├── Exploration Notebook.ipynb\n",
    "|   ├── Final Notebook.ipynb\n",
    "|   └── MVP Final Notebook.ipynb\n",
    "├── presentation.pdf\n",
    "└── README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'metrics' from 'sklearn' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-659070997a1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'metrics' from 'sklearn' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report,mean_squared_error, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (7,12,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# lets load in both datasets for each year\n",
    "symptoms20 = pd.read_csv('../data/2020/symptoms20.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "data20     = pd.read_csv('../data/2020/data20.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "vax20      = pd.read_csv('../data/2020/vax20.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "\n",
    "symptoms21 = pd.read_csv('../data/2021/symptoms21.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "data21     = pd.read_csv('../data/2021/data21.csv', index_col=['VAERS_ID'], encoding='latin-1')\n",
    "vax21      = pd.read_csv('../data/2021/vax21.csv', index_col=['VAERS_ID'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vax = pd.concat([vax20, vax21])\n",
    "combined_data = pd.concat([data20, data21])\n",
    "combined_symptoms = pd.concat([symptoms20, symptoms21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datavax = pd.merge(combined_data, combined_vax, on='VAERS_ID', how='right')\n",
    "dvs = pd.merge(datavax, combined_symptoms, on='VAERS_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating covid-19 vaccinations for the base dataframe\n",
    "df = dvs[dvs['VAX_TYPE'] == 'COVID19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-16cdb8520be8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-6f50c7f5c66d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DIED'] = df['DIED'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DIED'] = df['DIED'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SEX'] = df['SEX'].replace('U', '0')\n",
      "<ipython-input-38-6f50c7f5c66d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SEX'] = df['SEX'].replace('F', '0')\n",
      "<ipython-input-38-6f50c7f5c66d>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SEX'] = df['SEX'].replace('M', '1')\n",
      "<ipython-input-38-6f50c7f5c66d>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['L_THREAT'] = df['L_THREAT'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['L_THREAT'] = df['L_THREAT'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOSPITAL'] = df['HOSPITAL'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOSPITAL'] = df['HOSPITAL'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOSPDAYS'] = df['HOSPDAYS'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['X_STAY'] = df['X_STAY'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['X_STAY'] = df['X_STAY'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DISABLE'] = df['DISABLE'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DISABLE'] = df['DISABLE'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RECOVD'] = df['RECOVD'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RECOVD'] = df['RECOVD'].replace('U', 0)\n",
      "<ipython-input-38-6f50c7f5c66d>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RECOVD'] = df['RECOVD'].replace('N', 0)\n",
      "<ipython-input-38-6f50c7f5c66d>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RECOVD'] = df['RECOVD'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BIRTH_DEFECT'] = df['BIRTH_DEFECT'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BIRTH_DEFECT'] = df['BIRTH_DEFECT'].replace('Y', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].fillna(0)\n",
      "<ipython-input-38-6f50c7f5c66d>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].replace('7+', 7)\n",
      "<ipython-input-38-6f50c7f5c66d>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].replace('UNK', 1)\n",
      "<ipython-input-38-6f50c7f5c66d>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['NUMDAYS'] = df['NUMDAYS'].where(df['NUMDAYS']<120, 7)\n"
     ]
    }
   ],
   "source": [
    "df['DIED'] = df['DIED'].fillna(0)\n",
    "df['DIED'] = df['DIED'].replace('Y', 1)\n",
    "\n",
    "df['SEX'] = df['SEX'].replace('U', '0')\n",
    "df['SEX'] = df['SEX'].replace('F', '0')\n",
    "df['SEX'] = df['SEX'].replace('M', '1')\n",
    "\n",
    "df['L_THREAT'] = df['L_THREAT'].fillna(0)\n",
    "df['L_THREAT'] = df['L_THREAT'].replace('Y', 1)\n",
    "\n",
    "df['HOSPITAL'] = df['HOSPITAL'].fillna(0)\n",
    "df['HOSPITAL'] = df['HOSPITAL'].replace('Y', 1)\n",
    "\n",
    "df['HOSPDAYS'] = df['HOSPDAYS'].fillna(0)\n",
    "\n",
    "df['X_STAY'] = df['X_STAY'].fillna(0)\n",
    "df['X_STAY'] = df['X_STAY'].replace('Y', 1)\n",
    "\n",
    "df['DISABLE'] = df['DISABLE'].fillna(0)\n",
    "df['DISABLE'] = df['DISABLE'].replace('Y', 1)\n",
    "\n",
    "df['RECOVD'] = df['RECOVD'].fillna(0)\n",
    "df['RECOVD'] = df['RECOVD'].replace('U', 0)\n",
    "df['RECOVD'] = df['RECOVD'].replace('N', 0)\n",
    "df['RECOVD'] = df['RECOVD'].replace('Y', 1)\n",
    "\n",
    "df['BIRTH_DEFECT'] = df['BIRTH_DEFECT'].fillna(0)\n",
    "df['BIRTH_DEFECT'] = df['BIRTH_DEFECT'].replace('Y', 1)\n",
    "\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].fillna(0)\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].replace('7+', 7)\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].replace('UNK', 1)\n",
    "\n",
    "df['NUMDAYS'] = df['NUMDAYS'].where(df['NUMDAYS']<120, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-14e06d3e3430>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SEX'] = df['SEX'].astype(int)\n",
      "<ipython-input-39-14e06d3e3430>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['AGE_YRS'] = df['AGE_YRS'].fillna(50)\n",
      "<ipython-input-39-14e06d3e3430>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['AGE_YRS'] = df['AGE_YRS'].astype(int)\n",
      "<ipython-input-39-14e06d3e3430>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOSPDAYS'] = df['HOSPDAYS'].astype(int)\n",
      "<ipython-input-39-14e06d3e3430>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['NUMDAYS'] = df['NUMDAYS'].astype(int)\n",
      "<ipython-input-39-14e06d3e3430>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df['SEX'] = df['SEX'].astype(int)\n",
    "df['AGE_YRS'] = df['AGE_YRS'].fillna(50)\n",
    "df['AGE_YRS'] = df['AGE_YRS'].astype(int)\n",
    "df['HOSPDAYS'] = df['HOSPDAYS'].astype(int)\n",
    "df['NUMDAYS'] = df['NUMDAYS'].astype(int)\n",
    "df['VAX_DOSE_SERIES'] = df['VAX_DOSE_SERIES'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LA    39272\n",
       "RA    15127\n",
       "AR     1380\n",
       "UN     1207\n",
       "OT       35\n",
       "LL       29\n",
       "RL       10\n",
       "LG        3\n",
       "GM        3\n",
       "Name: VAX_SITE, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VAX_SITE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0eb0a9e7a600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlabel_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# lets clean up the state column by filling NaN values and binning the unusual locations as Other as there are only a few of each\n",
    "df['STATE'].replace(['AS', 'VI', 'MP', 'Ca', 'XB', 'FM', 'MH', 'GU'], 'OTH', inplace=True)\n",
    "df['STATE'] = df['STATE'].fillna('NA')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df['STATE'])\n",
    "df['STATE'] = label_encoder.transform(df['STATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaccine Manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there are no NaNs or unwanted values we can just fit and transform\n",
    "df['VAX_MANU'].value_counts()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df['VAX_MANU'])\n",
    "df['VAX_MANU'] = label_encoder.transform(df['VAX_MANU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injection Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the dose was applied, right arm, left arm, leg, ect.\n",
    "df['VAX_SITE'] = df['VAX_SITE'].fillna('NA')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df['VAX_SITE'])\n",
    "df['VAX_SITE'] = label_encoder.transform(df['VAX_SITE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states the method of delivering the vaccine, such as srynge, nasal, intradermal, intramuscular, and others\n",
    "df['VAX_ROUTE'] = df['VAX_ROUTE'].fillna('UN')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df['VAX_ROUTE'])\n",
    "df['VAX_ROUTE'] = label_encoder.transform(df['VAX_ROUTE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Administration Facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples of locations would be school, military, senior home ect.\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(df['V_ADMINBY'])\n",
    "df['V_ADMINBY'] = label_encoder.transform(df['V_ADMINBY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following columns cleaned cannot using LabelEncoder as many rows have multiple values to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the columns with text data is a little tricky as there is no standard format, many misspellings, and multiple values presented for many people\n",
    "# Lets begin by lowercasing the Allergies column\n",
    "df['ALLERGIES'] = df['ALLERGIES'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we replace all these different ways of saying none with none, as well as NaNs\n",
    "nonelist = ['no', 'no known allergies', 'unknown', 'none known', 'n/a', 'none reported', 'na', 'none.',\n",
    "            'no known drug allergies', 'no allergies', 'na', 'no known', 'no known allergies.', 'none listed', \n",
    "           'unk', 'none known.']\n",
    "\n",
    "df['ALLERGIES'] = df['ALLERGIES'].fillna('none')\n",
    "df['ALLERGIES'] = df['ALLERGIES'].replace('penicillin|sulfa', 'penicillin')\n",
    "df['ALLERGIES'] = df['ALLERGIES'].replace(nonelist, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions will find each list-like text and turn it into a format acceptable for get_dummies\n",
    "# We are using this method instead of onehotencoder or labelbinarizer so a row can have multiple allergies represented\n",
    "# by only using the allergies that at least thirty people have in the data, we can keep the dimensionality and required cleaning down\n",
    "# it is likely that an algorith would not be able to learn from allergies that have a very small representation\n",
    "allall = []\n",
    "for each in df['ALLERGIES']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "        \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "        \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>30].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "\n",
    "dummyframe = pd.Series(allall3).str.get_dummies()\n",
    "\n",
    "listy.remove('penicillin|sulfa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets attach our new columns to the dataframe\n",
    "df = df.join(dummyframe[listy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Illnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CUR_ILL'] = df['CUR_ILL'].str.lower()\n",
    "\n",
    "nonelist = ['no', 'unknown', 'none.', 'none reported', 'n/a', 'na', 'none known', 'denies', 'none noted', '0', 'no illness',\n",
    "           'none listed', 'not known', 'no known', 'non', 'no acute illnesses', 'no.', 'denied', 'see below', 'no illnesses',\n",
    "            'unk', 'unkown', 'none documented', 'none stated', 'nothing', 'none known.', 'unknown.', 'no known illnesses',\n",
    "            'n/a.','no e', 'none reported.', 'no acute illness']\n",
    "\n",
    "df['CUR_ILL'] = df['CUR_ILL'].fillna('none')\n",
    "df['CUR_ILL'] = df['CUR_ILL'].replace(nonelist, 'none')\n",
    "df['CUR_ILL'] = df['CUR_ILL'].replace(['covid 19', 'covid', 'covid- 19 diagnosis 12/11/2020 asymptomatic', 'covid-19 (diagnosed 10/26/20)', 'covid-19  (diagnosed 10/26/20)'], 'covid-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['CUR_ILL']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "        \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "        \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>13].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "    \n",
    "datufrayme = pd.Series(allall3).str.get_dummies()\n",
    "\n",
    "listy.remove('alcohol use disorder|facial laceration|alcohol intoxication|secondary syphillis')\n",
    "listy.remove('elevated troponin i level elevated troponin i level        elevated brain natriuretic peptide (bnp) level elevated brain natriuretic peptide (bnp) level        dyspnea       chest pain        atrial fibrillation with rapid ventricular response (hcc) atrial fibrillation with rapid ventricular response|initial encounter       hyponatremia hyponatremia')\n",
    "    \n",
    "df = df.join(datufrayme[listy], lsuffix=\" cur_ill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HISTORY'] = df['HISTORY'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quite a few entries for history need to be rectified, doubles were found using .value_counts() as we use the most common\n",
    "nonelist = ['no', 'unknown', 'none.', 'none reported', 'n/a', 'na', 'none known', 'denies', 'none noted', '0', 'no illness',\n",
    "           'none listed', 'not known', 'no known', 'non', 'no acute illnesses', 'no.', 'denied', 'see below', 'no illnesses',\n",
    "            'unk', 'unkown', 'none documented', 'none stated', 'nothing', 'none known.', 'unknown.', 'as above', 'no known illnesses',\n",
    "            'n/a.','no e', 'none reported.', 'medical history/concurrent conditions: no adverse event (no reported medical history)',\n",
    "           'medical history/concurrent conditions: no adverse event (no reported medical history.)', 'see above', 'medical history/concurrent conditions: no adverse event',\n",
    "           'medical history/concurrent conditions: no adverse event (no medical history reported.)', 'medical history/concurrent conditions: no adverse event (no medical history reported)',\n",
    "           'medical history/concurrent conditions: no adverse event (medical history not provided)', 'comments: list of non-encoded patient relevant history: patient other relevant history 1: none',\n",
    "           ]\n",
    "\n",
    "df['HISTORY'] = df['HISTORY'].fillna('none')\n",
    "df['HISTORY'] = df['HISTORY'].replace(nonelist, 'none')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: covid-19', 'covid-19')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: hypertension', 'hypertension')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: penicillin allergy', 'penicillin allergy')\n",
    "df['HISTORY'] = df['HISTORY'].replace(['medical history/concurrent conditions: asthma','mild asthma','exercise induced asthma'], 'asthma')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: blood pressure high', 'high blood pressure')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: sulfonamide allergy', 'sulfonamide allergy')\n",
    "df['HISTORY'] = df['HISTORY'].replace(['diabetic', 'type 2 diabetes', 'type 1 diabetes'], 'diabetes')\n",
    "df['HISTORY'] = df['HISTORY'].replace('medical history/concurrent conditions: migraine', 'migraines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['HISTORY']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "            \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "            \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>40].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "    \n",
    "datufrayme = pd.Series(allall3).str.get_dummies()\n",
    "\n",
    "listy.remove('cerebral palsy|anxiety|crohns|bipolar|gerd|nutrition deficiency|iron deficiency')\n",
    "    \n",
    "df = df.join(datufrayme[listy], lsuffix=\" history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OTHER_MEDS'] = df['OTHER_MEDS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelist = ['unknown', 'no', 'none.', 'n/a', 'none reported', 'unk', 'none known', ';', 'not known', 'na', 'denies', ';  ;', \n",
    "           'nothing']\n",
    "\n",
    "df['OTHER_MEDS'] = df['OTHER_MEDS'].fillna('none')\n",
    "df['OTHER_MEDS'] = df['OTHER_MEDS'].replace(nonelist, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allall = []\n",
    "for each in df['OTHER_MEDS']:\n",
    "    if ',' in each:\n",
    "        alls = each.split(',')\n",
    "        ally = []\n",
    "        for weach in alls:\n",
    "            ally.append(weach.strip())\n",
    "        allall.append(ally)\n",
    "    else:\n",
    "        allall.append(each)\n",
    "            \n",
    "allall2 = []\n",
    "for each in allall:\n",
    "    if type(each) == list:\n",
    "        welt = \"|\".join(each)\n",
    "        allall2.append(welt)\n",
    "    else:\n",
    "        allall2.append(each)\n",
    "            \n",
    "listy = list(pd.Series(allall2).value_counts()[pd.Series(allall2).value_counts()>20].index)\n",
    "allall3 = list(map(lambda x: 'none' if x not in listy else x, allall2))\n",
    "    \n",
    "datufrayme = pd.Series(allall3).str.get_dummies()\n",
    "    \n",
    "df = df.join(datufrayme[listy], lsuffix=\" meds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the columns with data that has been dummied, data that gives away the target such as days in hopital, \n",
    "#     columns of post-diagnosis information, and irrelavant colums such as Form Version\n",
    "df.drop(columns = ['RECVDATE', 'CAGE_MO', 'CAGE_YR', 'RPT_DATE', 'SYMPTOM_TEXT', 'DIED',\n",
    "                  'DATEDIED', 'L_THREAT', 'ER_VISIT', 'HOSPDAYS', 'X_STAY', 'RECOVD', 'VAX_DATE', 'ONSET_DATE',\n",
    "                  'NUMDAYS', 'LAB_DATA', 'V_FUNDBY', 'OTHER_MEDS', 'CUR_ILL', 'HISTORY', 'PRIOR_VAX', 'SPLTTYPE', \n",
    "                  'FORM_VERS', 'TODAYS_DATE', 'OFC_VISIT', 'ER_ED_VISIT', 'ALLERGIES', 'VAX_TYPE', 'VAX_LOT', \n",
    "                  'SYMPTOM1', 'SYMPTOM2','SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5','SYMPTOMVERSION1', 'SYMPTOMVERSION2',\n",
    "                   'SYMPTOMVERSION3','SYMPTOMVERSION4', 'SYMPTOMVERSION5', 'VAX_NAME', 'VAERS_ID'],\n",
    "       axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoricals = ['STATE', 'V_ADMINBY', 'VAX_MANU', 'VAX_ROUTE', 'VAX_SITE']\n",
    "# df[categoricals] = df[categoricals].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these columns do not need to be dummied, passing enable_categorical=True into the DMatrixs will allow it to process, but only\n",
    "#     if gpu is enabled and numerous other requirements are met.\n",
    "df = pd.concat([df,pd.get_dummies(df['STATE'], prefix='STATE: ')],axis=1).drop(['STATE'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['VAX_MANU'], prefix='BRAND: ')],axis=1).drop(['VAX_MANU'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['VAX_SITE'], prefix='VAX_SITE: ')],axis=1).drop(['VAX_SITE'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['VAX_ROUTE'], prefix='VAX_ROUTE: ')],axis=1).drop(['VAX_ROUTE'],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['V_ADMINBY'], prefix='ADMINBY: ')],axis=1).drop(['V_ADMINBY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use hospitalization as our target, if it performs well enough we can try the continious target hosp_days\n",
    "x = df.drop(columns = ['HOSPITAL'])\n",
    "y = df['HOSPITAL']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .2)\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing with Smote greatly increases our metrics on the train data, but returns the worst results we have seen on the val\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "X_train_oversampled, ytrain = sm.fit_sample(xtrain, ytrain)\n",
    "xtrain = pd.DataFrame(X_train_oversampled, columns=xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adasyn is an alternative to smote, aulthough they are very similar it is still worth attempting\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "# ada = ADASYN()\n",
    "# X_train_oversampled, ytrain = ada.fit_sample(xtrain, ytrain)\n",
    "# xtrain = pd.DataFrame(X_train_oversampled, columns=xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytrain, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_val = lr.predict(xval)\n",
    "recall_score(yval, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr, xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_las = LogisticRegression(penalty='l1', C=.001, solver='liblinear')\n",
    "lr_las.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators = 300, max_depth=5)\n",
    "xgb.fit(xtrain, ytrain)\n",
    "yhat_train = xgb.predict(xtrain)\n",
    "recall_score(ytrain, yhat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_val = xgb.predict(xval)\n",
    "recall_score(yval, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try using the simpler RandomOverSampler instead\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler()\n",
    "# X_train_oversampled, ytrain = ros.fit_sample(xtrain, ytrain)\n",
    "# xtrain = pd.DataFrame(X_train_oversampled, columns=xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hm, none of our oversampling technique improves our mode, maybe undersampling the larger of the classes?\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# rus = RandomUnderSampler()\n",
    "# X_train_oversampled, ytrain = rus.fit_sample(xtrain, ytrain)\n",
    "# xtrain = pd.DataFrame(X_train_oversampled, columns=xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunatley it seems that sampling our train data makes our model perform very poorly on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy Predict is a great tool to easily test your dataset across over thirty models\n",
    "# this gives us a head start in our modelling as we can begin from the best result below\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(xtrain, xval, ytrain, yval)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since Random Forests generated the best results, we should try and improve upon it\n",
    "rfc = RandomForestClassifier('n_estimators': 100,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap)\n",
    "rfc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rfc.predict(xtrain)\n",
    "plot_confusion_matrix(estimator=rfc, y_true=ytrain, X = xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rfc.predict(xval)\n",
    "plot_confusion_matrix(estimator=rfc, y_true=yval, X = xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_score(yval, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 8, cv = 3, verbose=3, n_jobs = -1)\n",
    "rf_random.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "#     predictions = model.predict(test_features)\n",
    "    return plot_confusion_matrix(model,test_features,test_labels, values_format = 'd')\n",
    "    \n",
    "#     errors = abs(predictions - test_labels)\n",
    "#     mape = 100 * np.mean(errors / test_labels)\n",
    "#     accuracy = 100 - mape\n",
    "#     print('Model Performance')\n",
    "#     print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "#     print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(xtrain, ytrain)\n",
    "base_accuracy = evaluate(base_model, xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix([[8707,  365],[ 937, 1264]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREES BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(X, y, **kwargs):\n",
    "    estimator = RandomForestClassifier(**kwargs)\n",
    "    cval = cross_val_score(estimator, X, y, scoring = 'roc_auc', cv = 4, verbose = 3, n_jobs = -1)\n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_optimise_rf(X, y, n_iter = 100):\n",
    "    def rf_crossval(n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf):\n",
    "        #Wrapper of RandomForest cross validation.\n",
    "        #Note the fixing of the inputs so they match the expected type\n",
    "        #(e.g n_estimators must be an integer)\n",
    "        return rf_cv(\n",
    "            X = X,\n",
    "            y = y,\n",
    "            class_weight = \"balanced\",\n",
    "            criterion = \"entropy\",\n",
    "            min_samples_leaf = round(min_samples_leaf),\n",
    "            min_samples_split = round(min_samples_split),\n",
    "            max_depth = round(max_depth),\n",
    "            n_estimators = round(n_estimators),\n",
    "            max_features = max(min(max_features, 0.999), 1e-3),\n",
    "            bootstrap = True\n",
    "        )\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f = rf_crossval,\n",
    "        pbounds = {\n",
    "            'max_depth': (5, 40),\n",
    "            'min_samples_split': (1, 40),\n",
    "            'min_samples_leaf': (1, 40),\n",
    "            \"n_estimators\" : (10, 1000),\n",
    "            \"max_features\" : (0.1, 0.999),\n",
    "        }\n",
    "    )\n",
    "    optimizer.maximize(n_iter = n_iter, init_points=10)\n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_optimise_rf(xtrain, ytrain, n_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final result: {'target': -0.07562485649557907, 'params': {'max_features': 0.14536396029573667, 'n_estimators': 274.5153933464836}}\n",
    "Final result: {'target': -0.10702808396076546, 'params': {'max_depth': 16.510516494808947, 'max_features': 0.9747272567894322, 'min_samples_leaf': 3.655444204049038, 'min_samples_split': 2.290201118341872, 'n_estimators': 212.19037867335334}}\n",
    "Final result: {'target': -0.09605024365610514, 'params': {'max_depth': 19.140093166281204, 'max_features': 0.4629993256585475, 'min_samples_leaf': 1.2047202438817228, 'min_samples_split': 3.034554465488434, 'n_estimators': 168.6328805540666}}\n",
    "    |  8        | -0.1029   |  27.54    |  0.999    |  1.0      |  22.93    |  687.6    |\n",
    "    |  10       | -0.08651  |  28.96    |  0.999    |  1.0      |  4.866    |  394.7    |\n",
    "    |  13       |  0.7182   |  40.0     |  0.1      |  7.443    |  40.0     |  290.6    |\n",
    "    |  16       |  0.8935   |  34.12    |  0.8473   |  1.495    |  1.954    |  135.4    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 135,\n",
    "                                   max_depth= 34.12, max_features= 0.8473,\n",
    "                                    min_samples_leaf= 1, min_samples_split= 2,\n",
    "                                   random_state=888)\n",
    "base_model.fit(xtrain, ytrain)\n",
    "base_accuracy = evaluate(base_model, xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 135, random_state=888)\n",
    "base_model.fit(xtrain, ytrain)\n",
    "base_accuracy = evaluate(base_model, xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(random_state=888, max_features= 0.5)\n",
    "base_model.fit(xtrain, ytrain)\n",
    "base_accuracy = evaluate(base_model, xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREES BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feauture_imp= list(zip(rfc.feature_importances_, xval.columns))\n",
    "sorted(feauture_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the best performing model was a random forest, we can try XGBoost as it is also based on random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost requires it own matrix type to be used\n",
    "# XGBoost was built with sparse data in mind, adding the missing paramater will greatly improve the efficiency of the training\n",
    "dtrain = xgb.DMatrix(xtrain, label=ytrain, missing=0)\n",
    "dtest  = xgb.DMatrix(xtest, label=ytest, missing=0)\n",
    "dval   = xgb.DMatrix(xval, label=yval, missing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define a parameter tuner using Bayesian Optimiization\n",
    "def bo_tune_xgb(max_depth, gamma ,learning_rate, scale_pos_weight, min_child_weight, colsample_bytree, subsample, alpha, lambd):\n",
    "    params = {'max_depth'       : int(max_depth),\n",
    "              'gamma'           : gamma,\n",
    "#               'n_estimators'    : int(n_estimators),\n",
    "              'learning_rate'   : learning_rate,\n",
    "              'alpha'           : alpha,\n",
    "              'lambda'          : lambd,\n",
    "              'subsample'       : subsample,\n",
    "              'eval_metric'     : 'rmse',\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'scale_pos_weight': scale_pos_weight,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'tree_method'     : 'gpu_hist'}\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=200, nfold=5)\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define the ranges that Bayesian Optimization is allowed to search through\n",
    "# these ranges are common parameter ranges that most models fall into\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth' : (1, 20),\n",
    "                        'gamma'            : (0, 2),\n",
    "                        'alpha'            : (0, 10),\n",
    "                        'lambd'           : (0,3),\n",
    "                        'subsample'        : (0,1),           \n",
    "                        'learning_rate'    : (0,2),\n",
    "#                         'n_estimators'     : (100,400),\n",
    "                        'scale_pos_weight' : (6,7),\n",
    "                        'min_child_weight' : (1,10),\n",
    "                        'colsample_bytree' : (0,1)} ,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here we search for the strongest parameter combination\n",
    "xgb_bo.maximize(n_iter=7, init_points=5, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .max returns the strongest parameters\n",
    "params = xgb_bo.max['params']\n",
    "\n",
    "# some of the parameters need to be whole numbers\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "# params['n_estimators'] = int(params['n_estimators'])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see our results for the train data\n",
    "xgb_opt= xgb.train(params, dtrain)\n",
    "predsopt = xgb_opt.predict(dtrain)\n",
    "print(classification_report(predsopt.round(), ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(predsopt.round(), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now for the validation\n",
    "predsoptval = xgb_opt.predict(dval)\n",
    "print(classification_report(predsoptval.round(), yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(predsoptval.round(), yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsoptval = xgb_opt.predict(dval)\n",
    "print(classification_report(predsoptval.round(), yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = xgb_opt.predict(dval)\n",
    "plot_confusion_matrix([[8707,  365],[ 937, 1264]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swish is a recent activation function that remedies the issues of ReLU\n",
    "def swish(x, b = 1):\n",
    "    return (x * sigmoid(b * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newmod():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(176, input_dim=len(xtrain.columns), activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(88, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(44, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(22, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(11, activation='swish'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "estimator = newmod()\n",
    "estimator.compile(optimizer='nadam', \n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = estimator.fit(xtrain, ytrain, epochs=100, validation_data=(xval, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "plt.plot(history_df['loss'], label='loss')\n",
    "plt.plot(history_df['val_loss'], label='val_loss')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_hyp(depth, bagging_temperature, iterations, learning_rate, random_strength, border_count):\n",
    "  params = {'depth': depth,\n",
    "#             'iterations' : int(iterations),\n",
    "            'learning_rate' : learning_rate,\n",
    "            'random_strength' : random_strength,\n",
    "            'bagging_temperature': bagging_temperature,\n",
    "            'border_count' : int(border_count),\n",
    "#             '12_leaf_reg' : leaf_reg,\n",
    "#             'scale_pos_weight' : scale_pos_weight,\n",
    "            \"eval_metric\": \"F1\",\n",
    "            \"loss_function\" : \"Logloss\",\n",
    "            \"verbose\": True,\n",
    "            \"task_type\" : \"GPU\",\n",
    "            \"devices\" : '0:1'}\n",
    "  params[ \"depth\"] = int(round(depth)) \n",
    "  params[\"bagging_temperature\"] = bagging_temperature\n",
    "#   params['iterations'] = int(iterations)\n",
    "  params['learning_rate'] = learning_rate\n",
    "  params['random_strength'] = random_strength\n",
    "#   params['']\n",
    "  \n",
    "  cat_feat = [] # Categorical features list\n",
    "  cv_dataset = cgb.Pool(data=xtrain,\n",
    "                  label=ytrain,\n",
    "                  cat_features=cat_feat)\n",
    "\n",
    "  scores = cgb.cv(cv_dataset,\n",
    "                  params,\n",
    "                  plot=True,\n",
    "                  fold_count=3)\n",
    "  return np.max(scores['test-F1-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = {'depth': (0, 10),\n",
    "       'iterations' : (500, 600),\n",
    "       'learning_rate' : (.01, 1),\n",
    "       'random_strength' : (.0000001,10),\n",
    "       'bagging_temperature': (0,1),\n",
    "       'border_count' : (1,255)\n",
    "#        '12_leaf_reg' : (2, 30),\n",
    "#        'scale_pos_weight' : (.01, 1)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Surrogate model\n",
    "optimizer = BayesianOptimization(cat_hyp, pds, random_state=2100)\n",
    "                                  \n",
    "# Optimize\n",
    "optimizer.maximize(init_points=3, n_iter=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['depth'] = int(params['depth'])\n",
    "params['iterations'] = int(params['iterations'])\n",
    "params['border_count'] = int(params['border_count'])\n",
    "\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_feat = []\n",
    "cv_dataset = cgb.Pool(data=xtrain,\n",
    "                label=ytrain.values)\n",
    "\n",
    "cgb_opt = cgb.train( cv_dataset, plot=True)\n",
    "predsopt = cgb_opt.predict(cv_dataset)\n",
    "print(classification_report(predsopt.round(), ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(predsopt.round(), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(clf,\n",
    "                    search_spaces,\n",
    "                    scoring=roc_auc,\n",
    "                    cv=skf,\n",
    "                    n_iter=100,\n",
    "                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "                    return_train_score=False,\n",
    "                    refit=True,\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "tuned_model = CatBoostClassifier(**best_params,task_type = \"GPU\",od_type='Iter',one_hot_max_size=10)\n",
    "tuned_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tuned_model.predict_proba(X_valid)[:, 1]\n",
    "valid_score = roc_auc_score(y_valid, y_pred)\n",
    "print('Validation ROC-AUC score:', valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = CatBoostClassifier(**best_params,task_type = \"GPU\",od_type='Iter',one_hot_max_size=10)\n",
    "tuned_model.fit(df_train_features,y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['AGE_YRS','SEX','HOSPITAL','DISABLE','BIRTH_DEFECT','VAX_DOSE_SERIES','none', 'cur_ill','nka','nkda','penicillin','sulfa','pcn','latex','codeine','amoxicillin','sulfa drugs','shellfish','morphine','bactrim','seasonal allergies cur_ill','erythromycin','aspirin','sulfa antibiotics','augmentin','lisinopril meds','lactose','denies','penicillins','bee stings','cipro','iodine','nickel','levaquin','seasonal','ceclor','percocet','compazine','gluten','nkma','doxycycline','nsaids','keflex','ibuprofen meds','naproxen','codiene','tree nuts','bee venom','peanuts','clindamycin','none history','covid-19 history','asthma history','uti','seasonal allergies history','sinus infection','hypertension history','diabetes history','migraines history','blood pressure high','urinary tract infection','migraine history','hypothyroidism history','allergies','anxiety history','diabetic','gerd history','cold','sinusitis','acid reflux','copd history','new diagnosis of t2dm','fibromyalgia history','rheumatoid arthritis history','none meds','asthma','hypertension','hypothyroidism','diabetes','high blood pressure','migraines','htn','covid-19','anxiety','gerd','obesity','depression','hypothyroid','arthritis','rheumatoid arthritis','high cholesterol','copd','seasonal allergies','penicillin allergy','fibromyalgia','migraine','pcos','hyperlipidemia','lupus','ibs','sulfonamide allergy','ulcerative colitis','psoriasis','adhd','none','multivitamin','tylenol','synthroid','levothyroxine','birth control','ibuprofen','vitamin d','lexapro','prenatal vitamins','zyrtec','adderall','zoloft','vitamins','lisinopril','prenatal vitamin','metformin','multi vitamin','multivitamins','losartan','prozac','wellbutrin','flonase','eliquis','metoprolol','vitamin c','nuvaring','atorvastatin','omeprazole','melatonin','insulin','birth control pill','multi-vitamin','mirena iud','acetaminophen','amlodipine','daily multivitamin','prilosec','sertraline','albuterol','vitamin d3','birth control pills','coumadin','allegra','benadryl','STATE: _0','STATE: _1','STATE: _2','STATE: _3','STATE: _4','STATE: _5','STATE: _6','STATE: _7','STATE: _8','STATE: _9','STATE: _10','STATE: _11','STATE: _12','STATE: _13','STATE: _14','STATE: _15','STATE: _16','STATE: _17','STATE: _18','STATE: _19','STATE: _20','STATE: _21','STATE: _22','STATE: _23','STATE: _24','STATE: _25','STATE: _26','STATE: _27','STATE: _28','STATE: _29','STATE: _30','STATE: _31','STATE: _32','STATE: _33','STATE: _34','STATE: _35','STATE: _36','STATE: _37','STATE: _38','STATE: _39','STATE: _40','STATE: _41','STATE: _42','STATE: _43','STATE: _44','STATE: _45','STATE: _46','STATE: _47','STATE: _48','STATE: _49','STATE: _50','STATE: _51','STATE: _52','STATE: _53','BRAND: _0','BRAND: _1','BRAND: _2','BRAND: _3','VAX_SITE: _0','VAX_SITE: _1','VAX_SITE: _2','VAX_SITE: _3','VAX_SITE: _4','VAX_SITE: _5','VAX_SITE: _6','VAX_SITE: _7','VAX_SITE: _8','VAX_SITE: _9','VAX_ROUTE: _0','VAX_ROUTE: _1','VAX_ROUTE: _2','VAX_ROUTE: _3','VAX_ROUTE: _4','VAX_ROUTE: _5','VAX_ROUTE: _6','ADMINBY: _0','ADMINBY: _1','ADMINBY: _2','ADMINBY: _3','ADMINBY: _4','ADMINBY: _5','ADMINBY: _6','ADMINBY: _7','ADMINBY: _8']\n",
    "df = pd.DataFrame(columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE_YRS :  <input type=\"checkbox\", name='AGE_YRS'> <br>\n",
      "SEX :  <input type=\"checkbox\", name='SEX'> <br>\n",
      "DISABLE :  <input type=\"checkbox\", name='DISABLE'> <br>\n",
      "BIRTH_DEFECT :  <input type=\"checkbox\", name='BIRTH_DEFECT'> <br>\n",
      "VAX_DOSE_SERIES :  <input type=\"checkbox\", name='VAX_DOSE_SERIES'> <br>\n",
      "none :  <input type=\"checkbox\", name='none'> <br>\n",
      "cur_ill :  <input type=\"checkbox\", name='cur_ill'> <br>\n",
      "nka :  <input type=\"checkbox\", name='nka'> <br>\n",
      "nkda :  <input type=\"checkbox\", name='nkda'> <br>\n",
      "penicillin :  <input type=\"checkbox\", name='penicillin'> <br>\n",
      "sulfa :  <input type=\"checkbox\", name='sulfa'> <br>\n",
      "pcn :  <input type=\"checkbox\", name='pcn'> <br>\n",
      "latex :  <input type=\"checkbox\", name='latex'> <br>\n",
      "codeine :  <input type=\"checkbox\", name='codeine'> <br>\n",
      "amoxicillin :  <input type=\"checkbox\", name='amoxicillin'> <br>\n",
      "sulfa drugs :  <input type=\"checkbox\", name='sulfa drugs'> <br>\n",
      "shellfish :  <input type=\"checkbox\", name='shellfish'> <br>\n",
      "morphine :  <input type=\"checkbox\", name='morphine'> <br>\n",
      "bactrim :  <input type=\"checkbox\", name='bactrim'> <br>\n",
      "seasonal allergies cur_ill :  <input type=\"checkbox\", name='seasonal allergies cur_ill'> <br>\n",
      "erythromycin :  <input type=\"checkbox\", name='erythromycin'> <br>\n",
      "aspirin :  <input type=\"checkbox\", name='aspirin'> <br>\n",
      "sulfa antibiotics :  <input type=\"checkbox\", name='sulfa antibiotics'> <br>\n",
      "augmentin :  <input type=\"checkbox\", name='augmentin'> <br>\n",
      "lisinopril meds :  <input type=\"checkbox\", name='lisinopril meds'> <br>\n",
      "lactose :  <input type=\"checkbox\", name='lactose'> <br>\n",
      "denies :  <input type=\"checkbox\", name='denies'> <br>\n",
      "penicillins :  <input type=\"checkbox\", name='penicillins'> <br>\n",
      "bee stings :  <input type=\"checkbox\", name='bee stings'> <br>\n",
      "cipro :  <input type=\"checkbox\", name='cipro'> <br>\n",
      "iodine :  <input type=\"checkbox\", name='iodine'> <br>\n",
      "nickel :  <input type=\"checkbox\", name='nickel'> <br>\n",
      "levaquin :  <input type=\"checkbox\", name='levaquin'> <br>\n",
      "seasonal :  <input type=\"checkbox\", name='seasonal'> <br>\n",
      "ceclor :  <input type=\"checkbox\", name='ceclor'> <br>\n",
      "percocet :  <input type=\"checkbox\", name='percocet'> <br>\n",
      "compazine :  <input type=\"checkbox\", name='compazine'> <br>\n",
      "gluten :  <input type=\"checkbox\", name='gluten'> <br>\n",
      "nkma :  <input type=\"checkbox\", name='nkma'> <br>\n",
      "doxycycline :  <input type=\"checkbox\", name='doxycycline'> <br>\n",
      "nsaids :  <input type=\"checkbox\", name='nsaids'> <br>\n",
      "keflex :  <input type=\"checkbox\", name='keflex'> <br>\n",
      "ibuprofen meds :  <input type=\"checkbox\", name='ibuprofen meds'> <br>\n",
      "naproxen :  <input type=\"checkbox\", name='naproxen'> <br>\n",
      "codiene :  <input type=\"checkbox\", name='codiene'> <br>\n",
      "tree nuts :  <input type=\"checkbox\", name='tree nuts'> <br>\n",
      "bee venom :  <input type=\"checkbox\", name='bee venom'> <br>\n",
      "peanuts :  <input type=\"checkbox\", name='peanuts'> <br>\n",
      "clindamycin :  <input type=\"checkbox\", name='clindamycin'> <br>\n",
      "none history :  <input type=\"checkbox\", name='none history'> <br>\n",
      "covid-19 history :  <input type=\"checkbox\", name='covid-19 history'> <br>\n",
      "asthma history :  <input type=\"checkbox\", name='asthma history'> <br>\n",
      "uti :  <input type=\"checkbox\", name='uti'> <br>\n",
      "seasonal allergies history :  <input type=\"checkbox\", name='seasonal allergies history'> <br>\n",
      "sinus infection :  <input type=\"checkbox\", name='sinus infection'> <br>\n",
      "hypertension history :  <input type=\"checkbox\", name='hypertension history'> <br>\n",
      "diabetes history :  <input type=\"checkbox\", name='diabetes history'> <br>\n",
      "migraines history :  <input type=\"checkbox\", name='migraines history'> <br>\n",
      "blood pressure high :  <input type=\"checkbox\", name='blood pressure high'> <br>\n",
      "urinary tract infection :  <input type=\"checkbox\", name='urinary tract infection'> <br>\n",
      "migraine history :  <input type=\"checkbox\", name='migraine history'> <br>\n",
      "hypothyroidism history :  <input type=\"checkbox\", name='hypothyroidism history'> <br>\n",
      "allergies :  <input type=\"checkbox\", name='allergies'> <br>\n",
      "anxiety history :  <input type=\"checkbox\", name='anxiety history'> <br>\n",
      "diabetic :  <input type=\"checkbox\", name='diabetic'> <br>\n",
      "gerd history :  <input type=\"checkbox\", name='gerd history'> <br>\n",
      "cold :  <input type=\"checkbox\", name='cold'> <br>\n",
      "sinusitis :  <input type=\"checkbox\", name='sinusitis'> <br>\n",
      "acid reflux :  <input type=\"checkbox\", name='acid reflux'> <br>\n",
      "copd history :  <input type=\"checkbox\", name='copd history'> <br>\n",
      "new diagnosis of t2dm :  <input type=\"checkbox\", name='new diagnosis of t2dm'> <br>\n",
      "fibromyalgia history :  <input type=\"checkbox\", name='fibromyalgia history'> <br>\n",
      "rheumatoid arthritis history :  <input type=\"checkbox\", name='rheumatoid arthritis history'> <br>\n",
      "none meds :  <input type=\"checkbox\", name='none meds'> <br>\n",
      "asthma :  <input type=\"checkbox\", name='asthma'> <br>\n",
      "hypertension :  <input type=\"checkbox\", name='hypertension'> <br>\n",
      "hypothyroidism :  <input type=\"checkbox\", name='hypothyroidism'> <br>\n",
      "diabetes :  <input type=\"checkbox\", name='diabetes'> <br>\n",
      "high blood pressure :  <input type=\"checkbox\", name='high blood pressure'> <br>\n",
      "migraines :  <input type=\"checkbox\", name='migraines'> <br>\n",
      "htn :  <input type=\"checkbox\", name='htn'> <br>\n",
      "covid-19 :  <input type=\"checkbox\", name='covid-19'> <br>\n",
      "anxiety :  <input type=\"checkbox\", name='anxiety'> <br>\n",
      "gerd :  <input type=\"checkbox\", name='gerd'> <br>\n",
      "obesity :  <input type=\"checkbox\", name='obesity'> <br>\n",
      "depression :  <input type=\"checkbox\", name='depression'> <br>\n",
      "hypothyroid :  <input type=\"checkbox\", name='hypothyroid'> <br>\n",
      "arthritis :  <input type=\"checkbox\", name='arthritis'> <br>\n",
      "rheumatoid arthritis :  <input type=\"checkbox\", name='rheumatoid arthritis'> <br>\n",
      "high cholesterol :  <input type=\"checkbox\", name='high cholesterol'> <br>\n",
      "copd :  <input type=\"checkbox\", name='copd'> <br>\n",
      "seasonal allergies :  <input type=\"checkbox\", name='seasonal allergies'> <br>\n",
      "penicillin allergy :  <input type=\"checkbox\", name='penicillin allergy'> <br>\n",
      "fibromyalgia :  <input type=\"checkbox\", name='fibromyalgia'> <br>\n",
      "migraine :  <input type=\"checkbox\", name='migraine'> <br>\n",
      "pcos :  <input type=\"checkbox\", name='pcos'> <br>\n",
      "hyperlipidemia :  <input type=\"checkbox\", name='hyperlipidemia'> <br>\n",
      "lupus :  <input type=\"checkbox\", name='lupus'> <br>\n",
      "ibs :  <input type=\"checkbox\", name='ibs'> <br>\n",
      "sulfonamide allergy :  <input type=\"checkbox\", name='sulfonamide allergy'> <br>\n",
      "ulcerative colitis :  <input type=\"checkbox\", name='ulcerative colitis'> <br>\n",
      "psoriasis :  <input type=\"checkbox\", name='psoriasis'> <br>\n",
      "adhd :  <input type=\"checkbox\", name='adhd'> <br>\n",
      "none :  <input type=\"checkbox\", name='none'> <br>\n",
      "multivitamin :  <input type=\"checkbox\", name='multivitamin'> <br>\n",
      "tylenol :  <input type=\"checkbox\", name='tylenol'> <br>\n",
      "synthroid :  <input type=\"checkbox\", name='synthroid'> <br>\n",
      "levothyroxine :  <input type=\"checkbox\", name='levothyroxine'> <br>\n",
      "birth control :  <input type=\"checkbox\", name='birth control'> <br>\n",
      "ibuprofen :  <input type=\"checkbox\", name='ibuprofen'> <br>\n",
      "vitamin d :  <input type=\"checkbox\", name='vitamin d'> <br>\n",
      "lexapro :  <input type=\"checkbox\", name='lexapro'> <br>\n",
      "prenatal vitamins :  <input type=\"checkbox\", name='prenatal vitamins'> <br>\n",
      "zyrtec :  <input type=\"checkbox\", name='zyrtec'> <br>\n",
      "adderall :  <input type=\"checkbox\", name='adderall'> <br>\n",
      "zoloft :  <input type=\"checkbox\", name='zoloft'> <br>\n",
      "vitamins :  <input type=\"checkbox\", name='vitamins'> <br>\n",
      "lisinopril :  <input type=\"checkbox\", name='lisinopril'> <br>\n",
      "prenatal vitamin :  <input type=\"checkbox\", name='prenatal vitamin'> <br>\n",
      "metformin :  <input type=\"checkbox\", name='metformin'> <br>\n",
      "multi vitamin :  <input type=\"checkbox\", name='multi vitamin'> <br>\n",
      "multivitamins :  <input type=\"checkbox\", name='multivitamins'> <br>\n",
      "losartan :  <input type=\"checkbox\", name='losartan'> <br>\n",
      "prozac :  <input type=\"checkbox\", name='prozac'> <br>\n",
      "wellbutrin :  <input type=\"checkbox\", name='wellbutrin'> <br>\n",
      "flonase :  <input type=\"checkbox\", name='flonase'> <br>\n",
      "eliquis :  <input type=\"checkbox\", name='eliquis'> <br>\n",
      "metoprolol :  <input type=\"checkbox\", name='metoprolol'> <br>\n",
      "vitamin c :  <input type=\"checkbox\", name='vitamin c'> <br>\n",
      "nuvaring :  <input type=\"checkbox\", name='nuvaring'> <br>\n",
      "atorvastatin :  <input type=\"checkbox\", name='atorvastatin'> <br>\n",
      "omeprazole :  <input type=\"checkbox\", name='omeprazole'> <br>\n",
      "melatonin :  <input type=\"checkbox\", name='melatonin'> <br>\n",
      "insulin :  <input type=\"checkbox\", name='insulin'> <br>\n",
      "birth control pill :  <input type=\"checkbox\", name='birth control pill'> <br>\n",
      "multi-vitamin :  <input type=\"checkbox\", name='multi-vitamin'> <br>\n",
      "mirena iud :  <input type=\"checkbox\", name='mirena iud'> <br>\n",
      "acetaminophen :  <input type=\"checkbox\", name='acetaminophen'> <br>\n",
      "amlodipine :  <input type=\"checkbox\", name='amlodipine'> <br>\n",
      "daily multivitamin :  <input type=\"checkbox\", name='daily multivitamin'> <br>\n",
      "prilosec :  <input type=\"checkbox\", name='prilosec'> <br>\n",
      "sertraline :  <input type=\"checkbox\", name='sertraline'> <br>\n",
      "albuterol :  <input type=\"checkbox\", name='albuterol'> <br>\n",
      "vitamin d3 :  <input type=\"checkbox\", name='vitamin d3'> <br>\n",
      "birth control pills :  <input type=\"checkbox\", name='birth control pills'> <br>\n",
      "coumadin :  <input type=\"checkbox\", name='coumadin'> <br>\n",
      "allegra :  <input type=\"checkbox\", name='allegra'> <br>\n",
      "benadryl :  <input type=\"checkbox\", name='benadryl'> <br>\n",
      "STATE: _0 :  <input type=\"checkbox\", name='STATE: _0'> <br>\n",
      "STATE: _1 :  <input type=\"checkbox\", name='STATE: _1'> <br>\n",
      "STATE: _2 :  <input type=\"checkbox\", name='STATE: _2'> <br>\n",
      "STATE: _3 :  <input type=\"checkbox\", name='STATE: _3'> <br>\n",
      "STATE: _4 :  <input type=\"checkbox\", name='STATE: _4'> <br>\n",
      "STATE: _5 :  <input type=\"checkbox\", name='STATE: _5'> <br>\n",
      "STATE: _6 :  <input type=\"checkbox\", name='STATE: _6'> <br>\n",
      "STATE: _7 :  <input type=\"checkbox\", name='STATE: _7'> <br>\n",
      "STATE: _8 :  <input type=\"checkbox\", name='STATE: _8'> <br>\n",
      "STATE: _9 :  <input type=\"checkbox\", name='STATE: _9'> <br>\n",
      "STATE: _10 :  <input type=\"checkbox\", name='STATE: _10'> <br>\n",
      "STATE: _11 :  <input type=\"checkbox\", name='STATE: _11'> <br>\n",
      "STATE: _12 :  <input type=\"checkbox\", name='STATE: _12'> <br>\n",
      "STATE: _13 :  <input type=\"checkbox\", name='STATE: _13'> <br>\n",
      "STATE: _14 :  <input type=\"checkbox\", name='STATE: _14'> <br>\n",
      "STATE: _15 :  <input type=\"checkbox\", name='STATE: _15'> <br>\n",
      "STATE: _16 :  <input type=\"checkbox\", name='STATE: _16'> <br>\n",
      "STATE: _17 :  <input type=\"checkbox\", name='STATE: _17'> <br>\n",
      "STATE: _18 :  <input type=\"checkbox\", name='STATE: _18'> <br>\n",
      "STATE: _19 :  <input type=\"checkbox\", name='STATE: _19'> <br>\n",
      "STATE: _20 :  <input type=\"checkbox\", name='STATE: _20'> <br>\n",
      "STATE: _21 :  <input type=\"checkbox\", name='STATE: _21'> <br>\n",
      "STATE: _22 :  <input type=\"checkbox\", name='STATE: _22'> <br>\n",
      "STATE: _23 :  <input type=\"checkbox\", name='STATE: _23'> <br>\n",
      "STATE: _24 :  <input type=\"checkbox\", name='STATE: _24'> <br>\n",
      "STATE: _25 :  <input type=\"checkbox\", name='STATE: _25'> <br>\n",
      "STATE: _26 :  <input type=\"checkbox\", name='STATE: _26'> <br>\n",
      "STATE: _27 :  <input type=\"checkbox\", name='STATE: _27'> <br>\n",
      "STATE: _28 :  <input type=\"checkbox\", name='STATE: _28'> <br>\n",
      "STATE: _29 :  <input type=\"checkbox\", name='STATE: _29'> <br>\n",
      "STATE: _30 :  <input type=\"checkbox\", name='STATE: _30'> <br>\n",
      "STATE: _31 :  <input type=\"checkbox\", name='STATE: _31'> <br>\n",
      "STATE: _32 :  <input type=\"checkbox\", name='STATE: _32'> <br>\n",
      "STATE: _33 :  <input type=\"checkbox\", name='STATE: _33'> <br>\n",
      "STATE: _34 :  <input type=\"checkbox\", name='STATE: _34'> <br>\n",
      "STATE: _35 :  <input type=\"checkbox\", name='STATE: _35'> <br>\n",
      "STATE: _36 :  <input type=\"checkbox\", name='STATE: _36'> <br>\n",
      "STATE: _37 :  <input type=\"checkbox\", name='STATE: _37'> <br>\n",
      "STATE: _38 :  <input type=\"checkbox\", name='STATE: _38'> <br>\n",
      "STATE: _39 :  <input type=\"checkbox\", name='STATE: _39'> <br>\n",
      "STATE: _40 :  <input type=\"checkbox\", name='STATE: _40'> <br>\n",
      "STATE: _41 :  <input type=\"checkbox\", name='STATE: _41'> <br>\n",
      "STATE: _42 :  <input type=\"checkbox\", name='STATE: _42'> <br>\n",
      "STATE: _43 :  <input type=\"checkbox\", name='STATE: _43'> <br>\n",
      "STATE: _44 :  <input type=\"checkbox\", name='STATE: _44'> <br>\n",
      "STATE: _45 :  <input type=\"checkbox\", name='STATE: _45'> <br>\n",
      "STATE: _46 :  <input type=\"checkbox\", name='STATE: _46'> <br>\n",
      "STATE: _47 :  <input type=\"checkbox\", name='STATE: _47'> <br>\n",
      "STATE: _48 :  <input type=\"checkbox\", name='STATE: _48'> <br>\n",
      "STATE: _49 :  <input type=\"checkbox\", name='STATE: _49'> <br>\n",
      "STATE: _50 :  <input type=\"checkbox\", name='STATE: _50'> <br>\n",
      "STATE: _51 :  <input type=\"checkbox\", name='STATE: _51'> <br>\n",
      "STATE: _52 :  <input type=\"checkbox\", name='STATE: _52'> <br>\n",
      "STATE: _53 :  <input type=\"checkbox\", name='STATE: _53'> <br>\n",
      "BRAND: _0 :  <input type=\"checkbox\", name='BRAND: _0'> <br>\n",
      "BRAND: _1 :  <input type=\"checkbox\", name='BRAND: _1'> <br>\n",
      "BRAND: _2 :  <input type=\"checkbox\", name='BRAND: _2'> <br>\n",
      "BRAND: _3 :  <input type=\"checkbox\", name='BRAND: _3'> <br>\n",
      "VAX_SITE: _0 :  <input type=\"checkbox\", name='VAX_SITE: _0'> <br>\n",
      "VAX_SITE: _1 :  <input type=\"checkbox\", name='VAX_SITE: _1'> <br>\n",
      "VAX_SITE: _2 :  <input type=\"checkbox\", name='VAX_SITE: _2'> <br>\n",
      "VAX_SITE: _3 :  <input type=\"checkbox\", name='VAX_SITE: _3'> <br>\n",
      "VAX_SITE: _4 :  <input type=\"checkbox\", name='VAX_SITE: _4'> <br>\n",
      "VAX_SITE: _5 :  <input type=\"checkbox\", name='VAX_SITE: _5'> <br>\n",
      "VAX_SITE: _6 :  <input type=\"checkbox\", name='VAX_SITE: _6'> <br>\n",
      "VAX_SITE: _7 :  <input type=\"checkbox\", name='VAX_SITE: _7'> <br>\n",
      "VAX_SITE: _8 :  <input type=\"checkbox\", name='VAX_SITE: _8'> <br>\n",
      "VAX_SITE: _9 :  <input type=\"checkbox\", name='VAX_SITE: _9'> <br>\n",
      "VAX_ROUTE: _0 :  <input type=\"checkbox\", name='VAX_ROUTE: _0'> <br>\n",
      "VAX_ROUTE: _1 :  <input type=\"checkbox\", name='VAX_ROUTE: _1'> <br>\n",
      "VAX_ROUTE: _2 :  <input type=\"checkbox\", name='VAX_ROUTE: _2'> <br>\n",
      "VAX_ROUTE: _3 :  <input type=\"checkbox\", name='VAX_ROUTE: _3'> <br>\n",
      "VAX_ROUTE: _4 :  <input type=\"checkbox\", name='VAX_ROUTE: _4'> <br>\n",
      "VAX_ROUTE: _5 :  <input type=\"checkbox\", name='VAX_ROUTE: _5'> <br>\n",
      "VAX_ROUTE: _6 :  <input type=\"checkbox\", name='VAX_ROUTE: _6'> <br>\n",
      "ADMINBY: _0 :  <input type=\"checkbox\", name='ADMINBY: _0'> <br>\n",
      "ADMINBY: _1 :  <input type=\"checkbox\", name='ADMINBY: _1'> <br>\n",
      "ADMINBY: _2 :  <input type=\"checkbox\", name='ADMINBY: _2'> <br>\n",
      "ADMINBY: _3 :  <input type=\"checkbox\", name='ADMINBY: _3'> <br>\n",
      "ADMINBY: _4 :  <input type=\"checkbox\", name='ADMINBY: _4'> <br>\n",
      "ADMINBY: _5 :  <input type=\"checkbox\", name='ADMINBY: _5'> <br>\n",
      "ADMINBY: _6 :  <input type=\"checkbox\", name='ADMINBY: _6'> <br>\n",
      "ADMINBY: _7 :  <input type=\"checkbox\", name='ADMINBY: _7'> <br>\n",
      "ADMINBY: _8 :  <input type=\"checkbox\", name='ADMINBY: _8'> <br>\n"
     ]
    }
   ],
   "source": [
    "for each in colnames:\n",
    "    print(f'{each} :  <input type=\"checkbox\", name={chr(39)}{each}{chr(39)}> <br>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try:\n",
      "    df['AGE_YRS'] = request.form['AGE_YRS']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['SEX'] = request.form['SEX']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['DISABLE'] = request.form['DISABLE']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['BIRTH_DEFECT'] = request.form['BIRTH_DEFECT']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_DOSE_SERIES'] = request.form['VAX_DOSE_SERIES']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['none'] = request.form['none']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['cur_ill'] = request.form['cur_ill']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['nka'] = request.form['nka']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['nkda'] = request.form['nkda']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['penicillin'] = request.form['penicillin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sulfa'] = request.form['sulfa']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['pcn'] = request.form['pcn']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['latex'] = request.form['latex']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['codeine'] = request.form['codeine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['amoxicillin'] = request.form['amoxicillin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sulfa drugs'] = request.form['sulfa drugs']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['shellfish'] = request.form['shellfish']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['morphine'] = request.form['morphine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['bactrim'] = request.form['bactrim']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['seasonal allergies cur_ill'] = request.form['seasonal allergies cur_ill']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['erythromycin'] = request.form['erythromycin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['aspirin'] = request.form['aspirin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sulfa antibiotics'] = request.form['sulfa antibiotics']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['augmentin'] = request.form['augmentin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['lisinopril meds'] = request.form['lisinopril meds']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['lactose'] = request.form['lactose']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['denies'] = request.form['denies']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['penicillins'] = request.form['penicillins']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['bee stings'] = request.form['bee stings']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['cipro'] = request.form['cipro']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['iodine'] = request.form['iodine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['nickel'] = request.form['nickel']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['levaquin'] = request.form['levaquin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['seasonal'] = request.form['seasonal']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ceclor'] = request.form['ceclor']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['percocet'] = request.form['percocet']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['compazine'] = request.form['compazine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['gluten'] = request.form['gluten']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['nkma'] = request.form['nkma']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['doxycycline'] = request.form['doxycycline']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['nsaids'] = request.form['nsaids']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['keflex'] = request.form['keflex']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ibuprofen meds'] = request.form['ibuprofen meds']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['naproxen'] = request.form['naproxen']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['codiene'] = request.form['codiene']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['tree nuts'] = request.form['tree nuts']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['bee venom'] = request.form['bee venom']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['peanuts'] = request.form['peanuts']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['clindamycin'] = request.form['clindamycin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['none history'] = request.form['none history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['covid-19 history'] = request.form['covid-19 history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['asthma history'] = request.form['asthma history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['uti'] = request.form['uti']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['seasonal allergies history'] = request.form['seasonal allergies history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sinus infection'] = request.form['sinus infection']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['hypertension history'] = request.form['hypertension history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['diabetes history'] = request.form['diabetes history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['migraines history'] = request.form['migraines history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['blood pressure high'] = request.form['blood pressure high']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['urinary tract infection'] = request.form['urinary tract infection']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['migraine history'] = request.form['migraine history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['hypothyroidism history'] = request.form['hypothyroidism history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['allergies'] = request.form['allergies']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['anxiety history'] = request.form['anxiety history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['diabetic'] = request.form['diabetic']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['gerd history'] = request.form['gerd history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['cold'] = request.form['cold']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sinusitis'] = request.form['sinusitis']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['acid reflux'] = request.form['acid reflux']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['copd history'] = request.form['copd history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['new diagnosis of t2dm'] = request.form['new diagnosis of t2dm']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['fibromyalgia history'] = request.form['fibromyalgia history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['rheumatoid arthritis history'] = request.form['rheumatoid arthritis history']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['none meds'] = request.form['none meds']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['asthma'] = request.form['asthma']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['hypertension'] = request.form['hypertension']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['hypothyroidism'] = request.form['hypothyroidism']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['diabetes'] = request.form['diabetes']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['high blood pressure'] = request.form['high blood pressure']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['migraines'] = request.form['migraines']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['htn'] = request.form['htn']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['covid-19'] = request.form['covid-19']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['anxiety'] = request.form['anxiety']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['gerd'] = request.form['gerd']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['obesity'] = request.form['obesity']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['depression'] = request.form['depression']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['hypothyroid'] = request.form['hypothyroid']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['arthritis'] = request.form['arthritis']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['rheumatoid arthritis'] = request.form['rheumatoid arthritis']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['high cholesterol'] = request.form['high cholesterol']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['copd'] = request.form['copd']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['seasonal allergies'] = request.form['seasonal allergies']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['penicillin allergy'] = request.form['penicillin allergy']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['fibromyalgia'] = request.form['fibromyalgia']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['migraine'] = request.form['migraine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['pcos'] = request.form['pcos']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['hyperlipidemia'] = request.form['hyperlipidemia']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['lupus'] = request.form['lupus']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ibs'] = request.form['ibs']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sulfonamide allergy'] = request.form['sulfonamide allergy']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ulcerative colitis'] = request.form['ulcerative colitis']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['psoriasis'] = request.form['psoriasis']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['adhd'] = request.form['adhd']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['none'] = request.form['none']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['multivitamin'] = request.form['multivitamin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['tylenol'] = request.form['tylenol']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['synthroid'] = request.form['synthroid']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['levothyroxine'] = request.form['levothyroxine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['birth control'] = request.form['birth control']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ibuprofen'] = request.form['ibuprofen']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['vitamin d'] = request.form['vitamin d']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['lexapro'] = request.form['lexapro']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['prenatal vitamins'] = request.form['prenatal vitamins']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['zyrtec'] = request.form['zyrtec']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['adderall'] = request.form['adderall']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['zoloft'] = request.form['zoloft']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['vitamins'] = request.form['vitamins']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['lisinopril'] = request.form['lisinopril']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['prenatal vitamin'] = request.form['prenatal vitamin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['metformin'] = request.form['metformin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['multi vitamin'] = request.form['multi vitamin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['multivitamins'] = request.form['multivitamins']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['losartan'] = request.form['losartan']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['prozac'] = request.form['prozac']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['wellbutrin'] = request.form['wellbutrin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['flonase'] = request.form['flonase']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['eliquis'] = request.form['eliquis']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['metoprolol'] = request.form['metoprolol']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['vitamin c'] = request.form['vitamin c']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['nuvaring'] = request.form['nuvaring']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['atorvastatin'] = request.form['atorvastatin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['omeprazole'] = request.form['omeprazole']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['melatonin'] = request.form['melatonin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['insulin'] = request.form['insulin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['birth control pill'] = request.form['birth control pill']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['multi-vitamin'] = request.form['multi-vitamin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['mirena iud'] = request.form['mirena iud']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['acetaminophen'] = request.form['acetaminophen']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['amlodipine'] = request.form['amlodipine']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['daily multivitamin'] = request.form['daily multivitamin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['prilosec'] = request.form['prilosec']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['sertraline'] = request.form['sertraline']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['albuterol'] = request.form['albuterol']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['vitamin d3'] = request.form['vitamin d3']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['birth control pills'] = request.form['birth control pills']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['coumadin'] = request.form['coumadin']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['allegra'] = request.form['allegra']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['benadryl'] = request.form['benadryl']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _0'] = request.form['STATE: _0']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _1'] = request.form['STATE: _1']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _2'] = request.form['STATE: _2']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _3'] = request.form['STATE: _3']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _4'] = request.form['STATE: _4']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _5'] = request.form['STATE: _5']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _6'] = request.form['STATE: _6']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _7'] = request.form['STATE: _7']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _8'] = request.form['STATE: _8']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _9'] = request.form['STATE: _9']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _10'] = request.form['STATE: _10']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _11'] = request.form['STATE: _11']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _12'] = request.form['STATE: _12']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _13'] = request.form['STATE: _13']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _14'] = request.form['STATE: _14']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _15'] = request.form['STATE: _15']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _16'] = request.form['STATE: _16']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _17'] = request.form['STATE: _17']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _18'] = request.form['STATE: _18']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _19'] = request.form['STATE: _19']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _20'] = request.form['STATE: _20']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _21'] = request.form['STATE: _21']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _22'] = request.form['STATE: _22']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _23'] = request.form['STATE: _23']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _24'] = request.form['STATE: _24']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _25'] = request.form['STATE: _25']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _26'] = request.form['STATE: _26']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _27'] = request.form['STATE: _27']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _28'] = request.form['STATE: _28']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _29'] = request.form['STATE: _29']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _30'] = request.form['STATE: _30']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _31'] = request.form['STATE: _31']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _32'] = request.form['STATE: _32']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _33'] = request.form['STATE: _33']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _34'] = request.form['STATE: _34']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _35'] = request.form['STATE: _35']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _36'] = request.form['STATE: _36']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _37'] = request.form['STATE: _37']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _38'] = request.form['STATE: _38']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _39'] = request.form['STATE: _39']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _40'] = request.form['STATE: _40']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _41'] = request.form['STATE: _41']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _42'] = request.form['STATE: _42']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _43'] = request.form['STATE: _43']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _44'] = request.form['STATE: _44']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _45'] = request.form['STATE: _45']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _46'] = request.form['STATE: _46']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _47'] = request.form['STATE: _47']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _48'] = request.form['STATE: _48']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _49'] = request.form['STATE: _49']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _50'] = request.form['STATE: _50']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _51'] = request.form['STATE: _51']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _52'] = request.form['STATE: _52']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['STATE: _53'] = request.form['STATE: _53']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['BRAND: _0'] = request.form['BRAND: _0']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['BRAND: _1'] = request.form['BRAND: _1']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['BRAND: _2'] = request.form['BRAND: _2']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['BRAND: _3'] = request.form['BRAND: _3']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _0'] = request.form['VAX_SITE: _0']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _1'] = request.form['VAX_SITE: _1']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _2'] = request.form['VAX_SITE: _2']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _3'] = request.form['VAX_SITE: _3']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _4'] = request.form['VAX_SITE: _4']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _5'] = request.form['VAX_SITE: _5']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _6'] = request.form['VAX_SITE: _6']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _7'] = request.form['VAX_SITE: _7']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _8'] = request.form['VAX_SITE: _8']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_SITE: _9'] = request.form['VAX_SITE: _9']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _0'] = request.form['VAX_ROUTE: _0']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _1'] = request.form['VAX_ROUTE: _1']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _2'] = request.form['VAX_ROUTE: _2']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _3'] = request.form['VAX_ROUTE: _3']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _4'] = request.form['VAX_ROUTE: _4']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _5'] = request.form['VAX_ROUTE: _5']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['VAX_ROUTE: _6'] = request.form['VAX_ROUTE: _6']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _0'] = request.form['ADMINBY: _0']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _1'] = request.form['ADMINBY: _1']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _2'] = request.form['ADMINBY: _2']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _3'] = request.form['ADMINBY: _3']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _4'] = request.form['ADMINBY: _4']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _5'] = request.form['ADMINBY: _5']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _6'] = request.form['ADMINBY: _6']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _7'] = request.form['ADMINBY: _7']\n",
      "except:\n",
      "    pass\n",
      "try:\n",
      "    df['ADMINBY: _8'] = request.form['ADMINBY: _8']\n",
      "except:\n",
      "    pass\n"
     ]
    }
   ],
   "source": [
    "for each in colnames:\n",
    "    print(\"try:\")\n",
    "    print(f'    df[{chr(39)}{each}{chr(39)}] = request.form[{chr(39)}{each}{chr(39)}]')\n",
    "    print('except:')\n",
    "    print(\"    pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['AGE_YRS','SEX','DISABLE','BIRTH_DEFECT','VAX_DOSE_SERIES','none', 'cur_ill','nka','nkda','penicillin','sulfa','pcn','latex','codeine','amoxicillin','sulfa drugs','shellfish','morphine','bactrim','seasonal allergies cur_ill','erythromycin','aspirin','sulfa antibiotics','augmentin','lisinopril meds','lactose','denies','penicillins','bee stings','cipro','iodine','nickel','levaquin','seasonal','ceclor','percocet','compazine','gluten','nkma','doxycycline','nsaids','keflex','ibuprofen meds','naproxen','codiene','tree nuts','bee venom','peanuts','clindamycin','none history','covid-19 history','asthma history','uti','seasonal allergies history','sinus infection','hypertension history','diabetes history','migraines history','blood pressure high','urinary tract infection','migraine history','hypothyroidism history','allergies','anxiety history','diabetic','gerd history','cold','sinusitis','acid reflux','copd history','new diagnosis of t2dm','fibromyalgia history','rheumatoid arthritis history','none meds','asthma','hypertension','hypothyroidism','diabetes','high blood pressure','migraines','htn','covid-19','anxiety','gerd','obesity','depression','hypothyroid','arthritis','rheumatoid arthritis','high cholesterol','copd','seasonal allergies','penicillin allergy','fibromyalgia','migraine','pcos','hyperlipidemia','lupus','ibs','sulfonamide allergy','ulcerative colitis','psoriasis','adhd','none','multivitamin','tylenol','synthroid','levothyroxine','birth control','ibuprofen','vitamin d','lexapro','prenatal vitamins','zyrtec','adderall','zoloft','vitamins','lisinopril','prenatal vitamin','metformin','multi vitamin','multivitamins','losartan','prozac','wellbutrin','flonase','eliquis','metoprolol','vitamin c','nuvaring','atorvastatin','omeprazole','melatonin','insulin','birth control pill','multi-vitamin','mirena iud','acetaminophen','amlodipine','daily multivitamin','prilosec','sertraline','albuterol','vitamin d3','birth control pills','coumadin','allegra','benadryl','STATE: _0','STATE: _1','STATE: _2','STATE: _3','STATE: _4','STATE: _5','STATE: _6','STATE: _7','STATE: _8','STATE: _9','STATE: _10','STATE: _11','STATE: _12','STATE: _13','STATE: _14','STATE: _15','STATE: _16','STATE: _17','STATE: _18','STATE: _19','STATE: _20','STATE: _21','STATE: _22','STATE: _23','STATE: _24','STATE: _25','STATE: _26','STATE: _27','STATE: _28','STATE: _29','STATE: _30','STATE: _31','STATE: _32','STATE: _33','STATE: _34','STATE: _35','STATE: _36','STATE: _37','STATE: _38','STATE: _39','STATE: _40','STATE: _41','STATE: _42','STATE: _43','STATE: _44','STATE: _45','STATE: _46','STATE: _47','STATE: _48','STATE: _49','STATE: _50','STATE: _51','STATE: _52','STATE: _53','BRAND: _0','BRAND: _1','BRAND: _2','BRAND: _3','VAX_SITE: _0','VAX_SITE: _1','VAX_SITE: _2','VAX_SITE: _3','VAX_SITE: _4','VAX_SITE: _5','VAX_SITE: _6','VAX_SITE: _7','VAX_SITE: _8','VAX_SITE: _9','VAX_ROUTE: _0','VAX_ROUTE: _1','VAX_ROUTE: _2','VAX_ROUTE: _3','VAX_ROUTE: _4','VAX_ROUTE: _5','VAX_ROUTE: _6','ADMINBY: _0','ADMINBY: _1','ADMINBY: _2','ADMINBY: _3','ADMINBY: _4','ADMINBY: _5','ADMINBY: _6','ADMINBY: _7','ADMINBY: _8']\n",
    "dfx = pd.DataFrame(columns=colnames) \n",
    "dfx['SEX'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.append(pd.Series(0, index=dfx.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>DISABLE</th>\n",
       "      <th>BIRTH_DEFECT</th>\n",
       "      <th>VAX_DOSE_SERIES</th>\n",
       "      <th>none</th>\n",
       "      <th>cur_ill</th>\n",
       "      <th>nka</th>\n",
       "      <th>nkda</th>\n",
       "      <th>...</th>\n",
       "      <th>VAX_ROUTE: _6</th>\n",
       "      <th>ADMINBY: _0</th>\n",
       "      <th>ADMINBY: _1</th>\n",
       "      <th>ADMINBY: _2</th>\n",
       "      <th>ADMINBY: _3</th>\n",
       "      <th>ADMINBY: _4</th>\n",
       "      <th>ADMINBY: _5</th>\n",
       "      <th>ADMINBY: _6</th>\n",
       "      <th>ADMINBY: _7</th>\n",
       "      <th>ADMINBY: _8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGE_YRS, SEX, HOSPITAL, DISABLE, BIRTH_DEFECT, VAX_DOSE_SERIES, none, cur_ill, nka, nkda, penicillin, sulfa, pcn, latex, codeine, amoxicillin, sulfa drugs, shellfish, morphine, bactrim, seasonal allergies cur_ill, erythromycin, aspirin, sulfa antibiotics, augmentin, lisinopril meds, lactose, denies, penicillins, bee stings, cipro, iodine, nickel, levaquin, seasonal, ceclor, percocet, compazine, gluten, nkma, doxycycline, nsaids, keflex, ibuprofen meds, naproxen, codiene, tree nuts, bee venom, peanuts, clindamycin, none history, covid-19 history, asthma history, uti, seasonal allergies history, sinus infection, hypertension history, diabetes history, migraines history, blood pressure high, urinary tract infection, migraine history, hypothyroidism history, allergies, anxiety history, diabetic, gerd history, cold, sinusitis, acid reflux, copd history, new diagnosis of t2dm, fibromyalgia history, rheumatoid arthritis history, none meds, asthma, hypertension, hypothyroidism, diabetes, high blood pressure, migraines, htn, covid-19, anxiety, gerd, obesity, depression, hypothyroid, arthritis, rheumatoid arthritis, high cholesterol, copd, seasonal allergies, penicillin allergy, fibromyalgia, migraine, pcos, hyperlipidemia, lupus, ibs, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 233 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=object)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['AGE_YRS','SEX','DISABLE','BIRTH_DEFECT','VAX_DOSE_SERIES','none', 'cur_ill','nka','nkda','penicillin','sulfa','pcn','latex','codeine','amoxicillin','sulfa drugs','shellfish','morphine','bactrim','seasonal allergies cur_ill','erythromycin','aspirin','sulfa antibiotics','augmentin','lisinopril meds','lactose','denies','penicillins','bee stings','cipro','iodine','nickel','levaquin','seasonal','ceclor','percocet','compazine','gluten','nkma','doxycycline','nsaids','keflex','ibuprofen meds','naproxen','codiene','tree nuts','bee venom','peanuts','clindamycin','none history','covid-19 history','asthma history','uti','seasonal allergies history','sinus infection','hypertension history','diabetes history','migraines history','blood pressure high','urinary tract infection','migraine history','hypothyroidism history','allergies','anxiety history','diabetic','gerd history','cold','sinusitis','acid reflux','copd history','new diagnosis of t2dm','fibromyalgia history','rheumatoid arthritis history','none meds','asthma','hypertension','hypothyroidism','diabetes','high blood pressure','migraines','htn','covid-19','anxiety','gerd','obesity','depression','hypothyroid','arthritis','rheumatoid arthritis','high cholesterol','copd','seasonal allergies','penicillin allergy','fibromyalgia','migraine','pcos','hyperlipidemia','lupus','ibs','sulfonamide allergy','ulcerative colitis','psoriasis','adhd','none','multivitamin','tylenol','synthroid','levothyroxine','birth control','ibuprofen','vitamin d','lexapro','prenatal vitamins','zyrtec','adderall','zoloft','vitamins','lisinopril','prenatal vitamin','metformin','multi vitamin','multivitamins','losartan','prozac','wellbutrin','flonase','eliquis','metoprolol','vitamin c','nuvaring','atorvastatin','omeprazole','melatonin','insulin','birth control pill','multi-vitamin','mirena iud','acetaminophen','amlodipine','daily multivitamin','prilosec','sertraline','albuterol','vitamin d3','birth control pills','coumadin','allegra','benadryl','STATE: _0','STATE: _1','STATE: _2','STATE: _3','STATE: _4','STATE: _5','STATE: _6','STATE: _7','STATE: _8','STATE: _9','STATE: _10','STATE: _11','STATE: _12','STATE: _13','STATE: _14','STATE: _15','STATE: _16','STATE: _17','STATE: _18','STATE: _19','STATE: _20','STATE: _21','STATE: _22','STATE: _23','STATE: _24','STATE: _25','STATE: _26','STATE: _27','STATE: _28','STATE: _29','STATE: _30','STATE: _31','STATE: _32','STATE: _33','STATE: _34','STATE: _35','STATE: _36','STATE: _37','STATE: _38','STATE: _39','STATE: _40','STATE: _41','STATE: _42','STATE: _43','STATE: _44','STATE: _45','STATE: _46','STATE: _47','STATE: _48','STATE: _49','STATE: _50','STATE: _51','STATE: _52','STATE: _53','BRAND: _0','BRAND: _1','BRAND: _2','BRAND: _3','VAX_SITE: _0','VAX_SITE: _1','VAX_SITE: _2','VAX_SITE: _3','VAX_SITE: _4','VAX_SITE: _5','VAX_SITE: _6','VAX_SITE: _7','VAX_SITE: _8','VAX_SITE: _9','VAX_ROUTE: _0','VAX_ROUTE: _1','VAX_ROUTE: _2','VAX_ROUTE: _3','VAX_ROUTE: _4','VAX_ROUTE: _5','VAX_ROUTE: _6','ADMINBY: _0','ADMINBY: _1','ADMINBY: _2','ADMINBY: _3','ADMINBY: _4','ADMINBY: _5','ADMINBY: _6','ADMINBY: _7','ADMINBY: _8']\n",
    "dfy = pd.DataFrame(columns=colnames)    \n",
    "dfy = dfy.append(pd.Series(0, index=dfy.columns), ignore_index=True)\n",
    "\n",
    "list(dfy.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
